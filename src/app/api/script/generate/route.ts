import { NextResponse } from 'next/server'

// Ensure Node runtime and extend max duration so long LLM calls don't 502
export const runtime = 'nodejs'
export const maxDuration = 60
import { generateScriptWithGemini, createGeminiSystemPrompt, DEFAULT_GEMINI_MODEL, validateGeminiConfig } from '@/lib/gemini'
// Keep OpenRouter as fallback
import { openrouter, DEFAULT_LLM_MODEL } from '@/lib/openrouter'

type OptionalSettings = {
  intent?: string
  genre?: string
  tone?: string
  audience?: string
  objective?: string
  keyMessage?: string
  language?: string
  constraints?: string
}

export async function POST(req: Request) {
  try {
    console.log('üé¨ Script generation API called')
    
    const body = await req.json()
    const userScript: string = body.userScript || ''
    const settings: OptionalSettings = body.settings || {}
    const useGemini: boolean = body.useGemini !== false // Default to true

    console.log('üìù Input data:', { userScriptLength: userScript.length, settings, useGemini })

    const lang = settings.language || 'English'

    const briefLines: string[] = []
    if (settings.intent) briefLines.push(`What: ${settings.intent}`)
    if (settings.genre) briefLines.push(`Genre: ${settings.genre}`)
    if (settings.tone) briefLines.push(`Tone/Mood: ${settings.tone}`)
    if (settings.audience) briefLines.push(`Target: ${settings.audience}`)
    if (settings.objective) briefLines.push(`Objective: ${settings.objective}`)
    if (settings.keyMessage) briefLines.push(`Key Message: ${settings.keyMessage}`)
    if (settings.constraints) briefLines.push(`Constraints: ${settings.constraints}`)

    const briefBlock = briefLines.length ? `# Brief\n${briefLines.join('\n')}\n` : ''
    const scriptBlock = userScript?.trim() ? `\n# User Script\n${userScript}` : ''

    // Build content for the model: Brief + User Script only
    const content = `${briefBlock}${scriptBlock}`
    
    console.log('üìã Content for LLM:', content.slice(0, 500) + '...')

    // Try Gemini first, fallback to OpenRouter if needed
    if (useGemini) {
      console.log('ü§ñ Attempting script generation with Gemini AI...')
      
      const geminiConfig = validateGeminiConfig()
      if (geminiConfig.isValid) {
        const systemPrompt = createGeminiSystemPrompt(lang)
        
        const geminiResult = await generateScriptWithGemini(
          content,
          DEFAULT_GEMINI_MODEL,
          {
            temperature: 0.7,
            maxTokens: 1200,
            systemInstruction: systemPrompt
          }
        )
        
        if (geminiResult.success && geminiResult.script) {
          console.log('‚úÖ Script generated successfully with Gemini')
          return NextResponse.json({ 
            script: geminiResult.script, 
            meta: { 
              ...geminiResult.meta,
              provider: 'gemini',
              model: DEFAULT_GEMINI_MODEL
            } 
          })
        } else {
          console.warn('‚ö†Ô∏è Gemini generation failed, falling back to OpenRouter:', geminiResult.error)
        }
      } else {
        console.warn('‚ö†Ô∏è Gemini not properly configured, using OpenRouter:', geminiConfig.error)
      }
    }

    // Fallback to OpenRouter
    console.log('ü§ñ Using OpenRouter as fallback...')
    const systemPrompt = `You are an award‚Äëwinning creative director and senior storyboard writer.

Your task: Generate or improve a production‚Äëready storyboard script by combining the Brief (optional settings) and the User Script (if provided). Always output in ${lang}.

Input signals you must use:
- Brief: Creative intent, genre, tone/mood, target audience, objective, key message, constraints. Treat constraints as hard requirements.
- User Script: If provided, preserve core structure, intention, brand voice, and factual content. You may tighten, reorder for pacing, and elevate clarity without losing meaning.

Hard rules:
1) Respect constraints strictly. If constraints conflict with user script, prefer constraints but minimally adjust the script to reconcile.
2) If both Brief and User Script are empty, infer minimally and produce a compact, high‚Äëquality default storyboard.
3) Keep the script lean, immediately actionable for visual production (no meta commentary). Aim for 6‚Äì12 shots unless the content clearly needs fewer/more.
4) Avoid clich√©s; write with clarity appropriate for the specified audience and tone. Keep terminology production‚Äëfriendly.
5) Names/brands/locations: If not specified, keep them generic.
6) Do not output JSON. Output must be Markdown with the exact labels below.

Output format (Markdown). For each shot, repeat the following block:

## Shot
Shot #: <number>
Shot Description: <concise action/visual summary>
Camera Shot: <size/type>
Angle: <camera angle or movement>
Background: <location or set/background cues>
Mood/Lighting: <tone, lighting, color cues>
Dialogue / VO: <dialogue or narration; omit if none>
Sound: <SFX/music; omit if none>

Begin the document with:

# Storyboard

## Summary
- 1‚Äì2 sentences capturing the story premise and goal (include target audience & tone).
`

    console.log('ü§ñ Calling OpenRouter with model:', DEFAULT_LLM_MODEL)
    
    const completion = await openrouter.chat.completions.create({
      model: DEFAULT_LLM_MODEL,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content }
      ],
      // OpenRouter SDK (OpenAI compat) may not accept provider-specific fields; keep to standard fields
      temperature: 0.7,
      max_tokens: 1200
    }, {
      timeout: 60000 // 60Ï¥à ÌÉÄÏûÑÏïÑÏõÉ
    })

    console.log('üéØ OpenRouter response received:', {
      hasChoices: !!completion.choices,
      choicesLength: completion.choices?.length || 0,
      firstChoiceContent: completion.choices?.[0]?.message?.content?.slice(0, 200),
      fullFirstChoice: completion.choices?.[0],
      fullMessage: completion.choices?.[0]?.message
    })

    // ÏùºÎ∂Ä Î™®Îç∏/ÌîÑÎ°úÎ∞îÏù¥ÎçîÎäî message.contentÎ•º Î¨∏ÏûêÏó¥Ïù¥ ÏïÑÎãå Î∞∞Ïó¥(part)Î°ú Î∞òÌôòÌï† Ïàò ÏûàÏúºÎØÄÎ°ú Î∞©Ïñ¥Ï†ÅÏúºÎ°ú Ï∂îÏ∂ú
    // GPT-5Îäî reasoning ÌïÑÎìúÏóê Ïã§Ï†ú ÎãµÎ≥ÄÏùÑ ÎÑ£Í≥† contentÎäî ÎπÑÏõåÎëò Ïàò ÏûàÏùå
    const normalizeContent = (msg: any): string => {
      console.log('üîç Normalizing content from message:', msg)
      
      const c = msg?.content
      const reasoning = msg?.reasoning
      
      // GPT-5Ïùò Í≤ΩÏö∞ reasoning ÌïÑÎìúÏóê Ïã§Ï†ú ÎãµÎ≥ÄÏù¥ ÏûàÏùÑ Ïàò ÏûàÏùå
      if (reasoning && typeof reasoning === 'string' && reasoning.trim()) {
        console.log('‚úÖ Reasoning content found (GPT-5 style):', reasoning.slice(0, 100))
        return reasoning.trim()
      }
      
      if (!c) {
        console.log('‚ùå No content found in message')
        return ''
      }
      
      if (typeof c === 'string') {
        console.log('‚úÖ String content found:', c.slice(0, 100))
        return c.trim()
      }
      
      if (Array.isArray(c)) {
        console.log('üìã Array content found, length:', c.length)
        const texts = c.map((p: any) => {
          if (typeof p === 'string') return p
          if (typeof p?.text === 'string') return p.text
          if (typeof p?.content === 'string') return p.content
          return ''
        })
        const result = texts.filter(Boolean).join('\n').trim()
        console.log('üìã Array content result:', result.slice(0, 100))
        return result
      }
      
      console.log('‚ùå Unknown content type:', typeof c)
      return ''
    }

    let script = ''
    if (Array.isArray(completion?.choices) && completion.choices.length > 0) {
      for (const ch of completion.choices) {
        const t = normalizeContent(ch?.message)
        if (t) { script = t; break }
      }
    }

    // ÏΩîÎìúÌéúÏä§Î°ú Í∞êÏãº Ï∂úÎ†• Î∞©ÏßÄ
    if (script) {
      script = script.replace(/^```(?:markdown|md)?\s*/i, '').replace(/\s*```$/i, '').trim()
    }

    console.log('üìÑ Final script:', {
      length: script.length,
      preview: script.slice(0, 300),
      isEmpty: !script
    })

    if (!script) {
      console.warn('‚ö†Ô∏è Empty script after first try ‚Äî retrying once with explicit instruction')
      const retry = await openrouter.chat.completions.create({
        model: DEFAULT_LLM_MODEL,
        messages: [
          { role: 'system', content: systemPrompt + '\n\nIMPORTANT: Output the final storyboard now in Markdown. Do not include any reasoning or commentary.' },
          { role: 'user', content }
        ],
        // Keep standard fields only
        temperature: 0.5,
        max_tokens: 1400
      }, { timeout: 60000 })

      console.log('üéØ Retry response received:', {
        hasChoices: !!retry.choices,
        choicesLength: retry.choices?.length || 0,
        firstChoiceContent: retry.choices?.[0]?.message?.content?.slice(0, 200)
      })

      if (Array.isArray(retry?.choices) && retry.choices.length > 0) {
        for (const ch of retry.choices) {
          const t = normalizeContent(ch?.message)
          if (t) { script = t; break }
        }
        if (script) {
          script = script.replace(/^```(?:markdown|md)?\s*/i, '').replace(/\s*```$/i, '').trim()
        }
      }
    }

    if (!script) {
      console.error('‚ùå Empty script after processing (including retry)')
      return NextResponse.json({ error: 'Empty response from model' }, { status: 502 })
    }

    console.log('‚úÖ Returning script to client')
    return NextResponse.json({ script, meta: { provider: 'openrouter', model: DEFAULT_LLM_MODEL } })
  } catch (err: any) {
    console.error('/api/script/generate error:', {
      message: err?.message,
      status: err?.status,
      code: err?.code,
      type: err?.type,
      stack: err?.stack
    })
    return NextResponse.json({ 
      error: err?.message || 'Generation failed',
      details: err?.status ? `API Error ${err.status}` : 'Unknown error'
    }, { status: 500 })
  }
}


